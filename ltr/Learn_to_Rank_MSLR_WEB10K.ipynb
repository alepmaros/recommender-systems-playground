{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lQHHQNzMkUz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBRanker\n",
    "from lightgbm import LGBMRanker, LGBMRegressor, LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_dict = {'k=5': {}, 'k=10': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "n_trials=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndcg(model, df, true_score, query_id, k=None):\n",
    "    predicted_score = model.predict(df)\n",
    "    \n",
    "    ndcg_df = pd.DataFrame({'query_id': query_id, 'true_score': true_score, 'predicted_score': predicted_score})\n",
    "    \n",
    "    true_score_test = ndcg_df.groupby(['query_id'])['true_score'].apply(list).tolist()\n",
    "    predicted_score_test = ndcg_df.groupby(['query_id'])['predicted_score'].apply(list).tolist()\n",
    "\n",
    "    return np.mean([ndcg_score([_true], [_predicted], k=k) for _true, _predicted in zip(true_score_test, predicted_score_test) if len(_true) > 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEzlMqWfNQB7"
   },
   "outputs": [],
   "source": [
    "def read_data(fold, filename):\n",
    "    df = pd.read_csv(f'D:/datasets/MSLR-WEB10K/{fold}/{filename}.txt', delimiter=\" \", header=None)\n",
    "    df = df.applymap(lambda x: x.split(\":\", 1)[-1] if type(x) == str else x)\n",
    "\n",
    "    y = df[0]\n",
    "    query_id = df[1]\n",
    "\n",
    "    group = df.groupby(1) # Group by based on query id\n",
    "    group_size = group.size().to_list()\n",
    "\n",
    "    df = df.drop([0, 1], axis=1) # Drop label and query id column\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df.astype(float) # Turn all to float\n",
    "    \n",
    "\n",
    "    return df, y, group_size, query_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCZP8dI5PwwM"
   },
   "outputs": [],
   "source": [
    "df_train, y_train, group_size_train, _ = read_data('Fold1', 'train')\n",
    "df_vali, y_vali, group_size_vali, query_id_vali = read_data('Fold1', 'vali')\n",
    "df_test, y_test, group_size_test, query_id_test = read_data('Fold1', 'test')\n",
    "\n",
    "X_columns = df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param_grid = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 300, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 100, 1000, step=100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 300),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    model = LGBMRanker(**param_grid)\n",
    "    model.fit(\n",
    "        df_train[X_columns],\n",
    "        y_train,\n",
    "        group=group_size_train,\n",
    "        eval_group=[group_size_vali],\n",
    "        eval_set=[(df_vali[X_columns], y_vali)],\n",
    "        early_stopping_rounds=150,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    ndcg = get_ndcg(model=model, df=df_test, true_score=y_test, query_id=query_id_test, k=10)\n",
    "    print(ndcg)\n",
    "    \n",
    "    trial.set_user_attr(key=\"best_booster\", value=model)\n",
    "    return ndcg\n",
    "\n",
    "def callback(study, trial):\n",
    "    if study.best_trial.number == trial.number:\n",
    "        study.set_user_attr(key=\"best_booster\", value=trial.user_attrs[\"best_booster\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"LGBM Ranker\")\n",
    "\n",
    "func = lambda trial: objective(trial)\n",
    "study.optimize(func, n_trials=n_trials, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_value, study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_regressor = LGBMRegressor()\n",
    "\n",
    "lgbm_regressor = lgbm_regressor.fit(\n",
    "    df_train[X_columns],\n",
    "    y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_ndcg(model=lgbm_regressor, df=df_test, true_score=y_test, query_id=query_id_test, k=k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_regressor(trial):\n",
    "    \n",
    "    param_grid = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 300, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 100, 1000, step=100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 300),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    model = LGBMRegressor(**param_grid)\n",
    "    model.fit(\n",
    "        df_train[X_columns],\n",
    "        y_train,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    ndcg = get_ndcg(model=model, df=df_test, true_score=y_test, query_id=query_id_test, k=10)\n",
    "    print(ndcg)\n",
    "    \n",
    "    return ndcg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"LGBM Regressor\")\n",
    "\n",
    "func = lambda trial: objective_regressor(trial)\n",
    "study.optimize(func, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_value, study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgboost(trial):\n",
    "    \n",
    "    param_grid = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_leaves\": trial.suggest_int(\"num_leaves\", 0, 300, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 300),\n",
    "        \"reg_alpha\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"reg_lambda\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "    }\n",
    "    \n",
    "    model = XGBRanker(objective=\"rank:pairwise\", **param_grid)\n",
    "    model.fit(\n",
    "        df_train[X_columns],\n",
    "        y_train,\n",
    "        group=group_size_train,\n",
    "        eval_group=[group_size_vali],\n",
    "        eval_set=[(df_vali[X_columns], y_vali)],\n",
    "        early_stopping_rounds=150,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    ndcg = get_ndcg(model=model, df=df_test, true_score=y_test, query_id=query_id_test, k=10)\n",
    "    print(ndcg)\n",
    "    \n",
    "    return ndcg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"XGBRanker\")\n",
    "\n",
    "func = lambda trial: objective_xgboost(trial)\n",
    "study.optimize(func, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_value, study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_ranker = XGBRanker(objective=\"rank:pairwise\")\n",
    "\n",
    "# xgb_ranker = xgb_ranker.fit(\n",
    "#     df_train[X_columns],\n",
    "#     y_train,\n",
    "#     group=group_size_train,\n",
    "#     eval_group=[group_size_vali],\n",
    "#     eval_set=[(df_vali[X_columns], y_vali)],\n",
    "#     early_stopping_rounds=150\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_ndcg(model=xgb_ranker, df=df_test, true_score=y_test, query_id=query_id_test, k=k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
